{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del visualize_detections\n",
    "import keras_cv\n",
    "import tensorflow as tf\n",
    "from adlc_util import visualize_dataset, visualize_detections\n",
    "\n",
    "class_mapping = {0:\"target\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this requires tensorflow>=2.14 on linux: https://github.com/XiaotingChen/maxatac_pip_1.0.5/issues/2\n",
    "train_ds = tf.data.Dataset.load(path=\"data/238_train_ds\", compression=\"GZIP\")\n",
    "test_ds = tf.data.Dataset.load(path=\"data/238_test_ds\", compression=\"GZIP\")\n",
    "\n",
    "augmenter = tf.keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(640, 640),\n",
    "            scale_factor=(0.75, 1.3),\n",
    "            bounding_box_format=\"xywh\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "inference_resizing = keras_cv.layers.Resizing(\n",
    "    640, 640, bounding_box_format=\"xywh\", pad_to_aspect_ratio=True\n",
    ")\n",
    "test_ds = test_ds.map(inference_resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# visualize_dataset(\n",
    "#     train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2, offset=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], keras_cv.bounding_box.to_dense(\n",
    "        inputs[\"bounding_boxes\"], max_boxes=32\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.005\n",
    "# including a global_clipnorm is extremely important in object detection tasks\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=base_lr, momentum=0.9, global_clipnorm=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone():\n",
    "    \"\"\"Builds ResNet50 with pre-trained imagenet weights\"\"\"\n",
    "    backbone = tf.keras.applications.ResNet50(\n",
    "        include_top=False, input_shape=[None, None, 3]\n",
    "    )\n",
    "    c3_output, c4_output, c5_output = [\n",
    "        backbone.get_layer(layer_name).output\n",
    "        for layer_name in [\"conv3_block4_out\", \"conv4_block6_out\", \"conv5_block3_out\"]\n",
    "    ]\n",
    "    return tf.keras.Model(\n",
    "        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n",
    "    )\n",
    "\n",
    "# resnet50_backbone = get_backbone()\n",
    "# model = keras_cv.models.RetinaNet(num_classes=1, backbone=resnet50_backbone, bounding_box_format=\"xywh\")\n",
    "\n",
    "model = keras_cv.models.RetinaNet(\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=keras_cv.models.ResNet50Backbone.from_preset(\n",
    "        \"resnet50_imagenet\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "prediction_decoder = keras_cv.layers.MultiClassNonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    # Decrease the required threshold to make predictions get pruned out\n",
    "    iou_threshold=0.2,\n",
    "    # Tune confidence threshold for predictions to pass NMS\n",
    "    confidence_threshold=0.7,\n",
    ")\n",
    "model.prediction_decoder = prediction_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    classification_loss=\"focal\",\n",
    "    box_loss=\"smoothl1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "    bounding_box_format=\"xywh\", evaluate_freq=20\n",
    ")\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    maxlen = max([len(key) for key in result.keys()])\n",
    "    print(\"Metrics:\")\n",
    "    print(\"-\" * (maxlen + 1))\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k.ljust(maxlen+1)}: {v.numpy():0.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "----------------------------\n",
      "MaP                         : 0.00\n",
      "MaP@[IoU=50]                : 0.00\n",
      "MaP@[IoU=75]                : 0.00\n",
      "MaP@[area=small]            : 0.00\n",
      "MaP@[area=medium]           : 0.00\n",
      "MaP@[area=large]            : 0.00\n",
      "Recall@[max_detections=1]   : 0.00\n",
      "Recall@[max_detections=10]  : 0.00\n",
      "Recall@[max_detections=100] : 0.00\n",
      "Recall@[area=small]         : 0.00\n",
      "Recall@[area=medium]        : 0.00\n",
      "Recall@[area=large]         : 0.00\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    classification_loss=\"focal\",\n",
    "    box_loss=\"smoothl1\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[coco_metrics],\n",
    ")\n",
    "coco_metrics.reset_state()\n",
    "result = model.evaluate(test_ds.take(1), verbose=0)\n",
    "result = coco_metrics.result(force=True)\n",
    "\n",
    "print_metrics(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.RetinaNet.from_preset(\n",
    "    \"resnet50_imagenet\",\n",
    "    num_classes=len(class_mapping),\n",
    "    # For more info on supported bounding box formats, visit\n",
    "    # https://keras.io/api/keras_cv/bounding_box/\n",
    "    bounding_box_format=\"xywh\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    classification_loss=\"focal\",\n",
    "    box_loss=\"smoothl1\",\n",
    "    optimizer=optimizer,\n",
    "    # We will use our custom callback to evaluate COCO metrics\n",
    "    metrics=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - ETA: 0s - loss: 0.3352 - box_loss: 0.1415 - classification_loss: 0.1936 - percent_boxes_matched_with_anchor: 0.9688         "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         logs\u001b[39m.\u001b[39mupdate(metrics)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m logs\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     train_ds\u001b[39m.\u001b[39;49mtake(\u001b[39m20\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mtest_ds\u001b[39m.\u001b[39;49mtake(\u001b[39m20\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# Run for 10-35~ epochs to achieve good scores.\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[EvaluateCOCOMetricsCallback(test_ds\u001b[39m.\u001b[39;49mtake(\u001b[39m20\u001b[39;49m))],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m )\n",
      "File \u001b[0;32m~/micromamba/envs/ncsuarc/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_epoch_end\u001b[39m(\u001b[39mself\u001b[39m, epoch, logs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mreset_state()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         images, y_true \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m], batch[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(images, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "class EvaluateCOCOMetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "            bounding_box_format=\"xywh\",\n",
    "            # passing 1e9 ensures we never evaluate until\n",
    "            # `metrics.result(force=True)` is\n",
    "            # called.\n",
    "            evaluate_freq=1e9,\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.metrics.reset_state()\n",
    "        for batch in tqdm.tqdm(self.data):\n",
    "            images, y_true = batch[0], batch[1]\n",
    "            y_pred = self.model.predict(images, verbose=0)\n",
    "            self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        metrics = self.metrics.result(force=True)\n",
    "        logs.update(metrics)\n",
    "        return logs\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_ds.take(20),\n",
    "    validation_data=test_ds.take(20),\n",
    "    # Run for 10-35~ epochs to achieve good scores.\n",
    "    epochs=1,\n",
    "    callbacks=[EvaluateCOCOMetricsCallback(test_ds.take(20))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_ds = test_ds.unbatch()\n",
    "visualization_ds = visualization_ds.ragged_batch(16)\n",
    "visualization_ds = visualization_ds.shuffle(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bounding_box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb Cell 18\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mprediction_decoder \u001b[39m=\u001b[39m keras_cv\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mMultiClassNonMaxSuppression(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     bounding_box_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mxywh\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     iou_threshold\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     confidence_threshold\u001b[39m=\u001b[39m\u001b[39m0.75\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ac/Source/ARC/adlc_cnn/test_pipeline.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m visualize_detections(model, dataset\u001b[39m=\u001b[39;49mvisualization_ds, bounding_box_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mxywh\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Source/ARC/adlc_cnn/adlc_util.py:29\u001b[0m, in \u001b[0;36mvisualize_detections\u001b[0;34m(model, dataset, bounding_box_format)\u001b[0m\n\u001b[1;32m     27\u001b[0m images, y_true \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m)))\n\u001b[1;32m     28\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(images)\n\u001b[0;32m---> 29\u001b[0m y_pred \u001b[39m=\u001b[39m bounding_box\u001b[39m.\u001b[39mto_ragged(y_pred)\n\u001b[1;32m     30\u001b[0m visualization\u001b[39m.\u001b[39mplot_bounding_box_gallery(\n\u001b[1;32m     31\u001b[0m     images,\n\u001b[1;32m     32\u001b[0m     value_range\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     class_mapping\u001b[39m=\u001b[39mclass_mapping,\n\u001b[1;32m     42\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bounding_box' is not defined"
     ]
    }
   ],
   "source": [
    "model.prediction_decoder = keras_cv.layers.MultiClassNonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    iou_threshold=0.5,\n",
    "    confidence_threshold=0.75,\n",
    ")\n",
    "\n",
    "visualize_detections(model, dataset=visualization_ds, bounding_box_format=\"xywh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizeDetections(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        visualize_detections(\n",
    "            self.model, bounding_box_format=\"xywh\", dataset=visualization_dataset\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
